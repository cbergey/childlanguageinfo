---
html_document:
  code_folding: show
author: "Claire Bergey and Dan Yurovsky"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
  pdf_document: null
  toc: no
number_sections: no
theme: lumen
title: "Entropy in child language"
toc: no
toc_float: no
---
  
```{r setup, include = FALSE}
library(knitr)

library(DBI)
library(here)
library(data.table)
library(tidytext)
library(RMySQL)
library(feather)
library(entropy)
library(tidyboot)
library(widyr)
library(feather)
library(tidyverse)

opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
               error = FALSE, cache = TRUE, tidy = FALSE)

# LDP auxiliary functions
source(here("helpers/read_ldp.R"))

theme_set(theme_classic(base_size = 14))
```

Read in conversation data
```{r, eval=T, message=FALSE, eval = F}
MIN_VISITS <- 5

Mode <- function(x) {
  x <- x[!is.na(x)]
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

#### Load and Clean Data
# Read in LDP data
ldp <- connect_to_ldp()

# subject demographics
demos <- get_table(ldp, "subjects") %>%
        filter(lesion == "") %>%
        select(id, sex, race, ethn) %>%
        collect()

# visits information and more subject demographics
visits <- get_table(ldp, "home_visits") %>%
  distinct(id, age_years, subject, visit_type, completed, income_category, 
           mother_education) %>%
  collect() %>%
  filter(visit_type != "SB5") %>%
  mutate(visit_type = as.numeric(gsub("[^0-9]", "", visit_type))) %>%
  rename(visit = visit_type) %>%
  mutate(completed = as.logical(completed),
         income_category = as.numeric(income_category))

subjs <- visits %>%
  group_by(subject) %>%
  summarise(completed = sum(completed),
            income_category = Mode(income_category),
            mother_education = Mode(mother_education)) %>%
  filter(completed >= 12) %>%
  select(-completed) %>%
  right_join(demos, by = c("subject" = "id"))

session_ages <- visits %>%
        filter(subject %in% subjs$subject, completed) %>%
        select(subject, visit, age_years) %>%
        rename(age = age_years) %>%
        arrange(subject, visit)
```

Get other measures
```{r load_measures, eval = F}
ppvt <- get_table(ldp, "ppvt") %>%
  collect() %>%
  select(-id) %>%
  rename(id = visit) %>%
  left_join(visits) %>%
  filter(subject %in% subjs$subject) %>%
  rename(ppvt = ppvt_raw) %>%
  select(subject, visit, age_years, ppvt)
  
cdi_ws <- get_table(ldp, "cdi_words_and_sentences") %>%
  select(id, visit, cdis_1a1_num, cdis_2e_num) %>%
  collect() %>%
  select(-id) %>%
  rename(id = visit) %>%
  left_join(visits) %>%
  filter(subject %in% subjs$subject) %>%
  rename(cdi_ws = cdis_1a1_num, sent_comp = cdis_2e_num) %>%
  select(subject, visit, age_years, cdi_ws, sent_comp) %>%
  arrange(subject, visit)

measures <- full_join(ppvt, cdi_ws, by = c("subject", "visit", "age_years")) %>%
  gather(measure, value, ppvt, cdi_ws) %>%
  filter(!is.na(value)) %>%
  arrange(subject, measure, visit) %>%
  mutate(person = "child")

#write_feather(measures, here("data/measures.feather"))
```

```{r setup_alignment, eval = F}
# read data from sql connection
utterances <- get_table(ldp, "utterances") %>%
  select(subject, session, line, p_chat, c_chat, p_utts, c_utts, p_mor, c_mor) %>%
  filter(p_chat != "" | c_chat != "") %>%
  collect() %>%
  filter(subject %in% unique(visits$id)) %>%
  mutate(order = 1:n())
  
# better organization of chat by person, subject, session, run
split_utts <- utterances %>%
  unnest_tokens(p_PoS, p_mor, drop=FALSE, token = stringr::str_split, pattern = " ") %>%
  unnest_tokens(c_PoS, c_mor, drop=FALSE, token = stringr::str_split, pattern = " ") %>%
  mutate(pos = if_else(!is.na(p_PoS), p_PoS, c_PoS)) %>%
  filter(pos != "") %>%
  separate(pos, into=c("pos", "word"), sep="\\|") %>%
  filter(!is.na(word)) %>%
  separate(word, into=c("word", "garbage"), sep= "[^[:alnum:]]") %>%
  mutate(stem = wordStem(word)) %>%  
  select(-garbage)

  gather(person, chat, c(p_chat, c_chat)) %>%
  mutate(person = if_else(person == "p_chat", "Parent", "Child")) %>%
  filter(chat != "") %>%
  arrange(order) %>%
  mutate(run = rleid(subject, session, person)) %>%
  group_by(run, subject, session, person) %>%
  summarise(chat = paste0(chat, collapse = " ")) 

#splits up run utterances into individual token words
tokens <- split_utts %>%
  unnest_tokens(word, chat) %>%
  arrange(run, subject, session) %>%
  filter(!word %in% c("xxx", "zzz", "zz"))

clean_utts <- utterances %>%
  select(-p_chat, -c_chat) %>%
  mutate(clean_p_utts = str_squish(str_replace_all(p_utts, "[^a-zA-Z']", " ")),
         clean_c_utts = str_squish(str_replace_all(c_utts, "[^a-zA-Z']", " ")),
         clean_p_utts = if_else(clean_p_utts == "", NA_character_, clean_p_utts),
         clean_c_utts = if_else(clean_c_utts == "", NA_character_, clean_c_utts),
         speaker = case_when(is.na(clean_p_utts) & !is.na(clean_c_utts) ~ "Target_Child",
                             is.na(clean_c_utts) & !is.na(clean_p_utts) ~ "Parent",
                             !is.na(clean_c_utts) & !is.na(clean_p_utts) ~ "Both"))
  
 
#write_feather(tokens, here("data/tokens.feather"))
```


```{r read-in}
tokens <- read_feather(here("data/tokens.feather"))
measures <- read_feather(here("data/measures.feather"))

types <- tokens %>%
  group_by(session, subject, person, word) %>%
  summarise(n = n()) 

words <- types %>%
  ungroup() %>%
  distinct(word)

n_words <- nrow(words)

session_tokens <- tokens %>%
  group_by(person, session, subject, word) %>%
  summarise(tokens = n()) %>%
  summarise(tokens = sum(tokens), types = n(), unsaid_types = n_words - types)
```


```{r smoothed_types}
smoothed_types <- types %>%
  left_join(session_tokens, by = c("subject", "session", "person")) %>%
  group_by(person, session, subject) %>%
  mutate(p = (n + 1/n_words)/(tokens + 1))
```

```{r kl-div}
p1 <- smoothed_types %>%
  filter(subject == 22, session == 4, person == "Parent")

p1_values <- smoothed_types %>%
  filter(subject == 22, session == 4, person == "Parent") %>%
  summarise(unsaid_p = (1/n_words)/(mean(tokens) + 1))

p2 <- smoothed_types %>%
  filter(subject == 22, session == 4, person == "Child")

p2_values <- smoothed_types %>%
  filter(subject == 22, session == 4, person == "Child") %>%
  summarise(unsaid_p = (1/n_words)/(mean(tokens) + 1))

kl_data <- bind_rows(p1, p2) %>%
  ungroup() %>%
  select(person, word, p) %>%
  spread(person, p) %>%
  mutate(Child = if_else(is.na(Child), pull(p2_values, unsaid_p), Child),
         Parent = if_else(is.na(Child), pull(p1_values, unsaid_p), Parent))
```

```{r entropy}
entropies <- smoothed_types %>%
  summarise(said_entropy = sum(-p * log(p)),
            unsaid_p = (1/n_words)/(mean(tokens) + 1),
            unsaid_types = mean(unsaid_types)) %>%
  mutate(entropy = said_entropy + unsaid_types*(- unsaid_p * log(unsaid_p))) %>%
  select(-unsaid_p, -unsaid_types)

group_entropies <- entropies %>%
  group_by(person, session) %>%
  tidyboot_mean(entropy)

ggplot(group_entropies,
       aes(x = session, y = empirical_stat)) + 
  facet_wrap(~ person) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(.25)) +
  labs(y = "entropy")
```

```{r, eval = F}
entropies %>%
  group_by(person, session) %>%
  mutate(entropy = scale(entropy)) %>%
  spread(person, entropy) %>%
  group_by(session) %>%
  summarise(cor = cor(Parent, Child, use = "complete")) %>%
  pull(cor) %>%
  hist()
```

```{r}
subj_measures <- measures %>%
  group_by(subject, measure) %>%
  summarise(value = mean(value, na.rm = T))
  
subj_entropies <- entropies %>%
  group_by(subject, person) %>%
  summarise(entropy = mean(entropy, na.rm = T)) %>%
  left_join(subj_measures) %>%
  filter(!is.na(measure)) %>%
  spread(measure, value) %>%
  gather(measure, value, entropy, cdi_ws, ppvt) %>%
  group_by(person, measure) %>%
  mutate(value = scale(value)) %>% 
  spread(measure, value) %>%
  filter(entropy > -4)

subj_entropies %>%
  select(subject, person, entropy) %>%
  spread(person, entropy) %>%
  ggplot(aes(x = Parent, y = Child)) + 
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(subj_entropies, aes(x = entropy, y = ppvt, color = person)) + 
  facet_wrap(~person) +
  geom_point() + 
  geom_smooth(method = "lm")

parents <- subj_entropies %>%
  filter(person == "Parent") %>%
  gather(measure, value, cdi_ws, entropy, ppvt) %>%
  pairwise_cor(measure, subject, value, use = "complete")

children <- subj_entropies %>%
  filter(person == "Child") %>%
  gather(measure, value, cdi_ws, entropy, ppvt) %>%
  pairwise_cor(measure, subject, value, use = "complete")

pairwise <- subj_entropies %>%
  select(subject, person, entropy) %>%
  spread(person, entropy) %>%
  summarise(cor = cor(Child, Parent))

```

```{r}
subj_entropies %>%
  left_join(select(session_tokens, subject, person, session, tokens) %>% 
              group_by(person, subject) %>%
              summarise(tokens = mean(tokens))) %>%
  group_by(person) %>%
  summarise(cor = cor(entropy, tokens, use = "complete"))
```


```{r process-for-crf}
processed_ldp <- split_utts %>%
  mutate(chat = str_remove(chat, "&")) %>%
  rename(file_id = session,
         child_id = subject,
         age_months = 14 + 4*session,
         tokens = chat,
         pos = part_of_speech,
         speaker = speaker_role) %>%
  mutate(index = 1:n() - 1)

```

