---
title: "htmm-hmm-processing"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(here)
library(feather)
library(tidyverse)
library(plotly)
library(reticulate)
library(entropy)
library(tidyboot)
library(randomizeR)
library(purrr)
library(gsl)
library(hash)
#code for connecting to ldp
  # note this file is not included in the public repo of this project
  # as it contains senstive access keys.
source(here("helpers/read_ldp.R"))
#establish connection, requires vpn to run sucessfully
ldp <- connect_to_ldp()
```

```{r}
list_tables <- function(connection) {
  DBI::dbListTables(connection)
}

get_table <- function(connection, name) {
  dplyr::tbl(connection, name)
}

list_tables(ldp)
subs <- get_table(ldp, "subjects") %>% collect()

#sub ids for typically developing kids
typ_kids <- subs %>%
  filter(lesion == "") %>% 
  filter(project == 2) %>% 
  pull(id)
```

```{r ldp}
#pull all the utterances
utts <- get_table(ldp, "utterances") %>%
  collect()


utts_clean <- utts %>%
  #include only typically developing participants
  filter(subject %in% typ_kids) %>%
  #drop the many things we don't care about
  select(subject, session, p_chat, p_mor)  %>%
  #add new utt_id variable
  mutate(utt_id= row_number())

PoS <- utts_clean %>% 
  unnest_tokens(PoS, p_mor, drop=FALSE, token = stringr::str_split, pattern = " ") %>%
  filter(PoS != "")

```

```{r read_feather}
framed_childes <- 
  read_feather(here("data/childes_parsed_frames.feather")) %>%
  mutate(transcript_id = as.numeric(transcript_id),
         utterance_order = as.numeric(utterance_order),
         target_child_age = as.numeric(target_child_age)) %>%
  filter(target_child_age <= 60) %>%
  filter(!str_detect(gloss, "yyy"),!str_detect(gloss, "xxx"),
         !is.na(target_child_age)) %>%
  mutate(speaker_code = ifelse(speaker_code == "MOM", "MOT", speaker_code),
         speaker_code = ifelse(speaker_code == "DAD", "FAT", speaker_code))
```

```{r filter}
cleaned_childes <- framed_childes %>%
  mutate(speaker_code = ifelse(speaker_code == "MOT" | speaker_code == "FAT", "PAR", speaker_code))

valid_transcripts <- cleaned_childes %>%
  filter(speaker_code == "CHI" | speaker_code == "PAR") %>%
  group_by(transcript_id, speaker_code) %>% count() %>%
  ungroup() %>%
  filter(n > 100) %>%
  group_by(transcript_id) %>% count() %>%
  filter(n == 2)
```

```{r clean}
cleaned_childes <- cleaned_childes %>% 
  filter(speaker_code == "CHI"| speaker_code == "PAR") %>% 
  mutate(age_in_months = floor(target_child_age)) %>% 
  filter(transcript_id %in% valid_transcripts$transcript_id) 

count_vector_frame <- cleaned_childes %>% 
  group_by(utt_parse, transcript_id, age_in_months, speaker_code) %>%
  count() %>% ungroup()

count_vector_gloss <- cleaned_childes %>%
  group_by(gloss, transcript_id, age_in_months, speaker_code) %>%
  count() %>% ungroup()
```

```{r for-hmm-frame}
# create a small set of conversations to run through the hmm
# add in frame type ids

sarah <- cleaned_childes %>%
  filter(target_child_id == 2971)

#hmm_transcripts_short <- cleaned_childes %>%
#  filter(target_child_age >= 48, target_child_age < 60) 

# create a dict of frame types
frame_dict <- cleaned_childes %>%
  count(utt_parse) %>%
  arrange(desc(n)) %>%
  filter(n > 1)

frame_dict <- frame_dict %>%
  filter(utt_parse %in% sarah$utt_parse)

frame_dict$id <- seq.int(nrow(frame_dict))
  
# create spacer rows to go between conversations
# last_utt <- sarah %>%
#   group_by(transcript_id) %>%
#   summarise(utterance_order = max(utterance_order)) %>%
#   mutate(utterance_order = utterance_order + 1,
#          utt_parse = "X", frame_id = 0) 

# put in frame ids
sarah <- sarah %>%
  mutate(frame_id = frame_dict[match(utt_parse,frame_dict$utt_parse),]$id) %>%
  arrange(transcript_id, utterance_order)
#bind_rows(last_utt) # for hmm

sarah <- sarah %>%
  mutate(frame_id = if_else(is.na(frame_id), 10362L, frame_id))

max <- sarah %>% distinct(frame_id) %>% arrange(desc(frame_id))
na <- sarah %>% filter(is.na(frame_id))

n_tokens = nrow(sarah)
n_types = sarah %>% distinct(frame_id) %>% nrow()

#write.csv(sarah$frame_id, here("data/sarah.txt"),
#          row.names = FALSE)

```

```{r make-htmm-file}

make_dict <- function(corpus) {
  dict <- corpus %>%
    mutate(word = strsplit(as.character(gloss), " ")) %>% 
    unnest(word) %>%
    distinct(word) %>%
    as_tibble(t(.))
  dict$id <- seq.int(nrow(dict))
  return(dict)
}


get_word_ids <- function(utterance) {
  words <- str_split(utterance, " ")
  id_sequence <- dict[match(words[[1]], dict$word),]$id %>%
    paste(sep = " ", collapse = " ") 
  return(id_sequence)
}
get_word_ids_v <- Vectorize(get_word_ids)

get_word_codes <- function(corpus) {
  corpus_coded <- corpus %>%
    mutate(word_ids = get_word_ids_v(gloss),
           sentence_length = str_count(word_ids, '\\w+')) %>%
    select(transcript_id, sentence_length, word_ids) %>%
    group_by(transcript_id) %>%
    mutate(g = group_indices()) %>%
    ungroup()
  return(corpus_coded)
}

dict <- make_dict(framed_childes)

childes_print <- get_word_codes(framed_childes)


for (i in 1:n_distinct(childes_print$g)) {
  transcript <- childes_print %>% filter(g == i) %>%
    select(!c(g, transcript_id))
  filename = paste0("data/childes_gloss/childes_gloss_for_htmm_", i)
  # write.table(transcript, filename, 
  #           append = FALSE, quote = FALSE, sep = " ", dec = " ",
  #           row.names = FALSE, col.names = FALSE)
}

for (i in 1:n_distinct(childes_print$g)) {
  text = paste0("childes_gloss_for_htmm_", i)
  #write(text, here("data/childes_gloss_doc_names"), append = TRUE)
}

#write.csv(dict, here("data/childes_gloss_word_dict.csv"))


```

```{r analyze-htmm}
# analyze htmm data
dict <- read_csv(here("data/childes_gloss_word_dict.csv"))
num_words = 46515
cols = as.character(c(1:num_words))
phi_vals <- read_tsv(here("data/childes_gloss_25.phi"), col_names = cols, skip = 1)
phi_vals$topic = seq.int(nrow(phi_vals))
phi_vals <- phi_vals %>% select(topic, everything()) %>%
  pivot_longer(cols = cols, names_to = "word_id", values_to = "phi") %>%
  mutate(word = dict[match(word_id,dict$id),]$word)

avg_topic <- phi_vals %>%
  group_by(word, word_id) %>%
  summarise(avg_phi = mean(phi))


phi_vals <- phi_vals %>%
  left_join(avg_topic) %>%
  mutate(phi_dev = phi - avg_phi)


phi_vals %>%
  group_by(topic) %>%
  arrange(desc(phi_dev)) %>%
  View()
  slice(1:20) %>%
  mutate(num = 1:20) %>%
  ungroup() %>%
  select(topic, num, word) %>%
  pivot_wider(names_from = topic, values_from = word) %>%
  View()

pdwz_vals_t <- read_tsv(here("data/childes_gloss_15.pdwz"))

topics = c(1:15) 
topics = sapply(topics, toString)
topics = paste0("topic_", topics)
topics_star = paste0(topics, "_*")

pdwz_vals <- pdwz_vals_t %>%
  mutate(doc_id = if_else(str_detect(topic_1, "d ="), 
                          as.numeric(str_remove(topic_1, "d = ")), NA_real_),
         utt_id = if_else(str_detect(topic_1, "i ="), 
                          as.numeric(str_remove(topic_1, "i = ")), NA_real_),
         utt_id = if_else(is.na(utt_id), lag(utt_id), utt_id)) %>%
  mutate_at(topics_star,  funs(gsub("[*]", "", .))) %>%
  fill(doc_id) %>%
  filter(!str_detect(topic_1, "=")) %>%
  mutate(doc_id = doc_id + 1, utt_id = utt_id + 1) %>%
  mutate_all(as.numeric)

pdwz_vals$max_topic <- apply(pdwz_vals %>% select(topics), 1, which.max)
pdwz_vals$max_topic_prob <- apply(pdwz_vals %>% select(topics), 1, max)
pdwz_vals$max_topic_star <- apply(pdwz_vals %>% select(topics_star), 1, which.max)
pdwz_vals$max_topic_star_prob <- apply(pdwz_vals %>% select(topics_star), 1, max)

```


```{r analyze-htmm}
# analyze htmm data
dict <- read_csv(here("data/childes_gloss_word_dict.csv"))
num_words = 46515
cols = as.character(c(1:num_words))
phi_vals <- read_tsv(here("data/childes_gloss_25.phi"), col_names = cols, skip = 1)
phi_vals$topic = seq.int(nrow(phi_vals))
phi_vals <- phi_vals %>% select(topic, everything()) %>%
  pivot_longer(cols = cols, names_to = "word_id", values_to = "phi") %>%
  mutate(word = dict[match(word_id,dict$id),]$word)

avg_topic <- phi_vals %>%
  group_by(word, word_id) %>%
  summarise(avg_phi = mean(phi))


phi_vals <- phi_vals %>%
  left_join(avg_topic) %>%
  mutate(phi_dev = phi - avg_phi)


phi_vals %>%
  group_by(topic) %>%
  arrange(desc(phi_dev)) %>%
  View()
  slice(1:20) %>%
  mutate(num = 1:20) %>%
  ungroup() %>%
  select(topic, num, word) %>%
  pivot_wider(names_from = topic, values_from = word) %>%
  View()

pdwz_vals_t <- read_tsv(here("data/childes_gloss_25.pdwz"))

topics = c(1:25) 
topics = sapply(topics, toString)
topics = paste0("topic_", topics)
topics_star = paste0(topics, "_*")

pdwz_vals <- pdwz_vals_t %>%
  mutate(doc_id = if_else(str_detect(topic_1, "d ="), 
                          as.numeric(str_remove(topic_1, "d = ")), NA_real_),
         utt_id = if_else(str_detect(topic_1, "i ="), 
                          as.numeric(str_remove(topic_1, "i = ")), NA_real_),
         utt_id = if_else(is.na(utt_id), lag(utt_id), utt_id)) %>%
  mutate_at(topics_star,  funs(gsub("[*]", "", .))) %>%
  fill(doc_id) %>%
  filter(!str_detect(topic_1, "=")) %>%
  mutate(doc_id = doc_id + 1, utt_id = utt_id + 1) %>%
  mutate_all(as.numeric)

pdwz_vals$max_topic <- apply(pdwz_vals %>% select(topics), 1, which.max)
pdwz_vals$max_topic_prob <- apply(pdwz_vals %>% select(topics), 1, max)
pdwz_vals$max_topic_star <- apply(pdwz_vals %>% select(topics_star), 1, which.max)
pdwz_vals$max_topic_star_prob <- apply(pdwz_vals %>% select(topics_star), 1, max)

```



```{r merge-pdwz}
childes_htmm <- framed_childes %>%
  group_by(transcript_id) %>%
  mutate(doc_id = group_indices(),
         utt_id = row_number(transcript_id)) %>%
  ungroup() %>%
  left_join(pdwz_vals, by = c("doc_id", "utt_id"))

#write_feather(childes_htmm, here("data/childes_htmm_25.feather"))
#write_csv(phi_vals, here("data/childes_phi_vals_25.csv"))
#write_csv(pdwz_vals, here("data/childes_pdwz_vals_25.csv"))
```

```{r hmm-from-htmm}
childes_htmm_select <- childes_htmm %>%
  filter(target_child_age > 36, target_child_age < 48) 
  
childes_htmm_select %>%
  distinct(max_topic) %>%
  arrange(desc(max_topic)) %>% View()

last_utt <- childes_htmm_select %>%
   group_by(transcript_id) %>%
   summarise(utterance_order = max(utterance_order)) %>%
   mutate(utterance_order = utterance_order + 1,
          max_topic = 0) 

childes_htmm_select <- childes_htmm_select %>%
  bind_rows(last_utt) %>%
  arrange(transcript_id, utterance_order) 
  
max <- childes_htmm_select %>% distinct(max_topic) %>% arrange(desc(max_topic))
na <- childes_htmm_select %>% filter(is.na(max_topic))

n_tokens = nrow(childes_htmm_select)
n_types = childes_htmm_select %>% distinct(max_topic) %>% nrow()

#write.csv(childes_htmm_select$max_topic, here("data/childes_topics_for_hmm.txt"),
#          row.names = FALSE)

```

```{r read-hmm}
childes_reconstruction <- read.csv(here("data/childes_topics_reconstruction.csv"))

childes_htmm_hmm <- childes_htmm_select %>%
  select(transcript_id, utterance_order, speaker_code, speaker_role,
         target_child_id, gloss, target_child_age, 
         utt_id, max_topic)

childes_htmm_hmm <- cbind(childes_htmm_hmm, childes_reconstruction)

childes_htmm_hmm <- childes_htmm_hmm %>%
  filter(max_topic != 0)

write_csv(childes_htmm_hmm, here("data/childes_htmm_hmm.csv"))
```
